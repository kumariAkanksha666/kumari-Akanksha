{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMF20v2ONdkbas1QH4xeh5o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumariAkanksha666/kumari-Akanksha/blob/main/Copy_of_food_analysis_project_akanksha_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bO6ldxDYaONJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51a39319-8ad2-4c45-e245-3bc70f88a2ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_815c939c-acfb-4693-ba43-0217cd46bce7\", \"food_waste.db\", 319488)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 0. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change working directory to a folder in your Drive so files are saved permanently\n",
        "import os\n",
        "os.makedirs('/content/drive/MyDrive/food_waste_project', exist_ok=True)\n",
        "os.chdir('/content/drive/MyDrive/food_waste_project')\n",
        "# 1. Import libraries\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# 2. Load CSV files\n",
        "providers_df = pd.read_csv(\"providers_data.csv\")\n",
        "receivers_df = pd.read_csv(\"receivers_data.csv\")\n",
        "food_listings_df = pd.read_csv(\"food_listings_data.csv\")\n",
        "claims_df = pd.read_csv(\"claims_data.csv\")\n",
        "\n",
        "# -------- Data Cleaning --------\n",
        "# Remove duplicates\n",
        "providers_df.drop_duplicates(inplace=True)\n",
        "receivers_df.drop_duplicates(inplace=True)\n",
        "food_listings_df.drop_duplicates(inplace=True)\n",
        "claims_df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Remove leading/trailing spaces in string columns\n",
        "for df in [providers_df, receivers_df, food_listings_df, claims_df]:\n",
        "    df.columns = df.columns.str.strip()  # clean column names\n",
        "    for col in df.select_dtypes(include=['object']).columns:\n",
        "        df[col] = df[col].str.strip()\n",
        "\n",
        "# Handle missing values\n",
        "providers_df.fillna({\"Name\": \"Unknown\", \"City\": \"Unknown\", \"Contact\": \"Unknown\"}, inplace=True)\n",
        "receivers_df.fillna({\"Name\": \"Unknown\", \"City\": \"Unknown\", \"Contact\": \"Unknown\"}, inplace=True)\n",
        "food_listings_df.fillna({\"Food_Name\": \"Unknown\", \"Location\": \"Unknown\", \"Food_Type\": \"Unknown\"}, inplace=True)\n",
        "claims_df.fillna({\"Status\": \"Unknown\"}, inplace=True)\n",
        "\n",
        "# Ensure date format is consistent (YYYY-MM-DD)\n",
        "food_listings_df['Expiry_Date'] = pd.to_datetime(food_listings_df['Expiry_Date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "# 3. Create SQLite DB and store cleaned tables\n",
        "conn = sqlite3.connect(\"food_waste.db\")\n",
        "providers_df.to_sql(\"providers\", conn, if_exists=\"replace\", index=False)\n",
        "receivers_df.to_sql(\"receivers\", conn, if_exists=\"replace\", index=False)\n",
        "food_listings_df.to_sql(\"food_listings\", conn, if_exists=\"replace\", index=False)\n",
        "claims_df.to_sql(\"claims\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "# 4. 15 SQL Queries\n",
        "q1 = pd.read_sql_query(\"\"\"\n",
        "SELECT p.City,\n",
        "COUNT(DISTINCT p.Provider_ID) AS Providers_Count,\n",
        "COUNT(DISTINCT r.Receiver_ID) AS Receivers_Count\n",
        "FROM providers p\n",
        "LEFT JOIN receivers r ON p.City = r.City\n",
        "GROUP BY p.City\n",
        "\"\"\", conn)\n",
        "\n",
        "q2 = pd.read_sql_query(\"\"\"\n",
        "SELECT Provider_Type,\n",
        "COUNT(*) AS Total_Listings\n",
        "FROM food_listings\n",
        "GROUP BY Provider_Type\n",
        "ORDER BY Total_Listings DESC\n",
        "\"\"\", conn)\n",
        "\n",
        "q3 = pd.read_sql_query(\"\"\"\n",
        "SELECT Name, Contact\n",
        "FROM providers\n",
        "WHERE City = 'Chennai'\n",
        "\"\"\", conn)\n",
        "\n",
        "q4 = pd.read_sql_query(\"\"\"\n",
        "SELECT r.Name, COUNT(c.Claim_ID) AS Total_Claims\n",
        "FROM receivers r\n",
        "JOIN claims c ON r.Receiver_ID = c.Receiver_ID\n",
        "GROUP BY r.Name\n",
        "ORDER BY Total_Claims DESC\n",
        "\"\"\", conn)\n",
        "\n",
        "q5 = pd.read_sql_query(\"\"\"\n",
        "SELECT SUM(Quantity) AS Total_Quantity_Available\n",
        "FROM food_listings\n",
        "\"\"\", conn)\n",
        "\n",
        "q6 = pd.read_sql_query(\"\"\"\n",
        "SELECT Location AS City, COUNT(*) AS Listings_Count\n",
        "FROM food_listings\n",
        "GROUP BY Location\n",
        "ORDER BY Listings_Count DESC\n",
        "\"\"\", conn)\n",
        "\n",
        "q7 = pd.read_sql_query(\"\"\"\n",
        "SELECT Food_Type, COUNT(*) AS Count\n",
        "FROM food_listings\n",
        "GROUP BY Food_Type\n",
        "ORDER BY Count DESC\n",
        "\"\"\", conn)\n",
        "\n",
        "q8 = pd.read_sql_query(\"\"\"\n",
        "SELECT f.Food_Name, COUNT(c.Claim_ID) AS Claims_Count\n",
        "FROM food_listings f\n",
        "LEFT JOIN claims c ON f.Food_ID = c.Food_ID\n",
        "GROUP BY f.Food_Name\n",
        "ORDER BY Claims_Count DESC\n",
        "\"\"\", conn)\n",
        "\n",
        "q9 = pd.read_sql_query(\"\"\"\n",
        "SELECT p.Name, COUNT(c.Claim_ID) AS Successful_Claims\n",
        "FROM providers p\n",
        "JOIN food_listings f ON p.Provider_ID = f.Provider_ID\n",
        "JOIN claims c ON f.Food_ID = c.Food_ID\n",
        "WHERE c.Status = 'Completed'\n",
        "GROUP BY p.Name\n",
        "ORDER BY Successful_Claims DESC\n",
        "\"\"\", conn)\n",
        "\n",
        "q10 = pd.read_sql_query(\"\"\"\n",
        "SELECT Status,\n",
        "ROUND((COUNT() * 100.0 / (SELECT COUNT() FROM claims)), 2) AS Percentage\n",
        "FROM claims\n",
        "GROUP BY Status\n",
        "\"\"\", conn)\n",
        "\n",
        "q11 = pd.read_sql_query(\"\"\"\n",
        "SELECT r.Name, ROUND(AVG(f.Quantity), 2) AS Avg_Quantity_Claimed\n",
        "FROM receivers r\n",
        "JOIN claims c ON r.Receiver_ID = c.Receiver_ID\n",
        "JOIN food_listings f ON c.Food_ID = f.Food_ID\n",
        "GROUP BY r.Name\n",
        "\"\"\", conn)\n",
        "\n",
        "q12 = pd.read_sql_query(\"\"\"\n",
        "SELECT Meal_Type, COUNT(*) AS Claims_Count\n",
        "FROM food_listings f\n",
        "JOIN claims c ON f.Food_ID = c.Food_ID\n",
        "GROUP BY Meal_Type\n",
        "ORDER BY Claims_Count DESC\n",
        "\"\"\", conn)\n",
        "\n",
        "q13 = pd.read_sql_query(\"\"\"\n",
        "SELECT p.Name, SUM(f.Quantity) AS Total_Donated\n",
        "FROM providers p\n",
        "JOIN food_listings f ON p.Provider_ID = f.Provider_ID\n",
        "GROUP BY p.Name\n",
        "ORDER BY Total_Donated DESC\n",
        "\"\"\", conn)\n",
        "\n",
        "q14 = pd.read_sql_query(\"\"\"\n",
        "SELECT Food_Name, Expiry_Date\n",
        "FROM food_listings\n",
        "WHERE DATE(Expiry_Date) <= DATE('now', '+2 days')\n",
        "\"\"\", conn)\n",
        "\n",
        "q15 = pd.read_sql_query(\"\"\"\n",
        "SELECT f.Location AS City,\n",
        "COUNT(DISTINCT f.Food_ID) AS Donations,\n",
        "COUNT(DISTINCT c.Claim_ID) AS Claims\n",
        "FROM food_listings f\n",
        "JOIN claims c ON f.Food_ID = c.Food_ID\n",
        "GROUP BY f.Location\n",
        "ORDER BY Donations DESC, Claims DESC\n",
        "\"\"\", conn)\n",
        "\n",
        "# 5. Save database and close connection\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "# 6. Download the SQLite database to your computer\n",
        "from google.colab import files\n",
        "files.download(\"food_waste.db\")"
      ]
    }
  ]
}